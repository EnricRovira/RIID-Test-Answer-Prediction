{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# 0. Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_profiling as pp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "    \n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import models, layers, regularizers, constraints, metrics, losses, optimizers\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://arxiv.org/abs/2010.12042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# 1. Load Data\n",
    "\n",
    "path = '../01_Data/01_Raw/'\n",
    "path_output = '../01_Data/02_GeneratedData/'\n",
    "\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# 2. Global Variables\n",
    "\n",
    "SEQ_LENGTH = 100\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# 3. Load Data\n",
    "\n",
    "path_input = path_output + 'train/'\n",
    "\n",
    "X_past_questions = np.load(path_input + 'X_past_questions.npy')\n",
    "X_past_responses = np.load(path_input + 'X_past_responses.npy')\n",
    "X_past_times = np.load(path_input + 'X_past_times.npy')\n",
    "X_agg_content_features = np.load(path_input + 'X_agg_content_features.npy')\n",
    "X_agg_user_features = np.load(path_input + 'X_agg_user_features.npy')\n",
    "X_curr_question_ids = np.load(path_input + 'X_curr_question_ids.npy')\n",
    "X_curr_question_tags = np.load(path_input + 'X_curr_question_tags.npy')\n",
    "X_target = np.load(path_input + 'X_target.npy')\n",
    "\n",
    "unique_users = np.load(path_input + 'unique_users.npy', allow_pickle=True)\n",
    "dict_users = np.load(path_input + 'dict_users.npy', allow_pickle=True)\n",
    "dict_users_inv = np.load(path_input + 'dict_users_inv.npy', allow_pickle=True)\n",
    "\n",
    "unique_users = unique_users.flatten()[0]\n",
    "dict_users = dict_users.flatten()[0]\n",
    "dict_users_inv = dict_users_inv.flatten()[0]\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# 4. Data Generator\n",
    "\n",
    "class RIIDDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, users, dict_users, batch_size, training=True):\n",
    "        super(RIIDDataGenerator, self).__init__()\n",
    "        \n",
    "        self.users = users\n",
    "        self.dict_users = dict_users\n",
    "        self.batch_size = batch_size\n",
    "        self.training = training\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        self.num_steps = int(np.ceil(len(self.users) / self.batch_size))\n",
    "        return self.num_steps\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        list_batch_users = [self.users[k] for k in indexes]\n",
    "        positions = [self.dict_users[u] for u in list_batch_users]\n",
    "        \n",
    "        batch = (X_past_questions[positions], X_past_responses[positions], X_past_times[positions],\n",
    "                 X_agg_content_features[positions], X_agg_user_features[positions], X_curr_question_ids[positions],\n",
    "                 X_curr_question_tags[positions])\n",
    "        \n",
    "        if self.training:\n",
    "            return batch, X_target[positions]\n",
    "        else:\n",
    "            return batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.users))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        \n",
    "        \n",
    "    def generateOrderedSequences(self, list_users):\n",
    "        pass\n",
    "    \n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_generator = RIIDDataGenerator(list(unique_users), dict_users, batch_size=8, training=True)\n",
    "\n",
    "# for batch in X_generator:\n",
    "#     break\n",
    "    \n",
    "# len(batch[0]), batch[0][0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# 5. Models\n",
    "\n",
    "class ReturnBestEarlyStopping(tf.keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReturnBestEarlyStopping, self).__init__(**kwargs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {self.stopped_epoch + 1}: early stopping')\n",
    "        elif self.restore_best_weights:\n",
    "            if self.verbose > 0:\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            \n",
    "\n",
    "class CustomEmbedding(models.Model):\n",
    "    def __init__(self, input_dim, output_dim, mask_value=-1, **kwargs):\n",
    "        super(CustomEmbedding, self).__init__(**kwargs, name='CustomEmbedding')\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.mask_value = mask_value\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embeddings = self.add_weight(\n",
    "            shape=(self.input_dim, self.output_dim),\n",
    "            initializer=\"random_normal\",\n",
    "            dtype=\"float32\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.embedding_lookup(self.embeddings, inputs)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if not self.mask_value:\n",
    "            return 0\n",
    "        return tf.not_equal(inputs, self.mask_value)\n",
    "    \n",
    "\n",
    "class CustomEmbeddingNormLayer(models.Model):\n",
    "    def __init__(self, input_dim, output_dim, rate=0.1, mask_value=-1, **kwargs):\n",
    "        super(CustomEmbeddingNormLayer, self).__init__(**kwargs, name='CustomEmbeddingNormLayer')\n",
    "\n",
    "        self.embedding = CustomEmbedding(input_dim=input_dim, output_dim=output_dim, mask_value=mask_value)\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "        self.layernorm = layers.LayerNormalization(epsilon=1e-6)\n",
    "            \n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        \n",
    "        x = self.embedding(inputs)\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        return x   \n",
    "\n",
    "class MultiHeadAttention(models.Model):\n",
    "    def __init__(self, d_model, num_heads, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs, name='MultiHeadAttention')\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = layers.Dense(d_model)\n",
    "        self.wk = layers.Dense(d_model)\n",
    "        self.wv = layers.Dense(d_model)\n",
    "\n",
    "        self.dense = layers.Dense(d_model)\n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention((q, k, v, mask))\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def scaled_dot_product_attention(self, inputs):\n",
    "        q, k, v, mask = inputs\n",
    "        \"\"\"Calculate the attention weights.\n",
    "        q, k, v must have matching leading dimensions.\n",
    "        k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "        The mask has different shapes depending on its type(padding or look ahead) \n",
    "        but it must be broadcastable for addition.\n",
    "\n",
    "        Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable \n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "        output, attention_weights\n",
    "        \"\"\"\n",
    "\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "        # scale matmul_qk\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        # add the mask to the scaled tensor.\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "        # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "        # add up to 1.\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "    \n",
    "class BaseModel(models.Model):\n",
    "    def __init__(self, d_model, num_heads, **kwargs):\n",
    "        super(BaseModel, self).__init__(**kwargs, name='BaseModel')\n",
    "        \n",
    "#         self.embed_question_id = CustomEmbedding(input_dim=13_523, output_dim=128, mask_value=-1)\n",
    "#         self.embed_question_parts = CustomEmbedding(input_dim=7, output_dim=128, mask_value=-1)\n",
    "#         self.embed_question_tags = CustomEmbedding(input_dim=189, output_dim=128, mask_value=-1)\n",
    "        \n",
    "#         self.embed_time_elapsed = CustomEmbedding(input_dim=300, output_dim=128, mask_value=-1)\n",
    "#         self.embed_time_lag = CustomEmbedding(input_dim=1440, output_dim=128, mask_value=-1)\n",
    "\n",
    "        self.embed_question_id = CustomEmbeddingNormLayer(input_dim=13_523, output_dim=128, mask_value=-1)\n",
    "        self.embed_question_parts = CustomEmbeddingNormLayer(input_dim=7, output_dim=128, mask_value=-1)\n",
    "        self.embed_question_correct_answer = CustomEmbeddingNormLayer(input_dim=4, output_dim=128, mask_value=-1)\n",
    "        self.embed_question_tags = CustomEmbeddingNormLayer(input_dim=189, output_dim=128, mask_value=-1)\n",
    "        \n",
    "        self.embed_time_elapsed = CustomEmbeddingNormLayer(input_dim=300, output_dim=128, mask_value=-1)\n",
    "        self.embed_time_lag = CustomEmbeddingNormLayer(input_dim=1440, output_dim=128, mask_value=-1)\n",
    "        \n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.layernorm4 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm5 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "#         self.gru_questions = layers.GRU(32, return_sequences=False, dropout=0.2, kernel_regularizer=regularizers.l2(1e-4))\n",
    "#         self.gru_responses = layers.GRU(32, return_sequences=False, dropout=0.2, kernel_regularizer=regularizers.l2(1e-4))\n",
    "        self.drop_1 = layers.Dropout(0.4)\n",
    "        self.dense = layers.Dense(64, activation=None, kernel_regularizer=regularizers.l2(1e-4))\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.drop_2 = layers.Dropout(0.3)\n",
    "        \n",
    "        self.dense_output = layers.Dense(1, activation='sigmoid')\n",
    "        self.mask_questions = layers.Lambda(lambda x: tf.not_equal(x, -1))\n",
    "        self.mask_responses = layers.Lambda(lambda x: tf.not_equal(x, -1))\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        \n",
    "        self.mask = layers.Lambda(lambda x: tf.not_equal(x, -1))\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        batch_past_questions, batch_past_responses, batch_past_times, \\\n",
    "        batch_agg_content_features, batch_agg_user_features, batch_curr_question_ids, \\\n",
    "        batch_curr_question_tags = inputs[0], inputs[1], inputs[2], inputs[3], inputs[4], inputs[5], inputs[6]\n",
    "        \n",
    "        ## Past\n",
    "        \n",
    "        # Questions\n",
    "        batch_past_question_id = self.embed_question_id(tf.cast(batch_past_questions[:, :, 0], tf.int64), training)\n",
    "        batch_past_question_part = self.embed_question_parts(tf.cast(batch_past_questions[:, :, 1], tf.int32), training)\n",
    "        batch_past_question_correct_answer = self.embed_question_correct_answer(tf.cast(batch_past_questions[:, :, 2], \n",
    "                                                                                        tf.int32), \n",
    "                                                                       training)\n",
    "        \n",
    "        batch_past_question_tags = self.embed_question_tags(tf.cast(batch_past_questions[:, :, 3:], tf.int32), training)     \n",
    "        \n",
    "        # Responses\n",
    "        batch_past_user_answered_correct = tf.expand_dims(batch_past_responses[:, :, 0], -1)\n",
    "        batch_past_user_answered_answer = self.embed_question_correct_answer(\n",
    "                                               tf.cast(batch_past_responses[:, :, 1], tf.int32), training)\n",
    "        \n",
    "        # Times\n",
    "        batch_past_times_elapsed = self.embed_time_elapsed(tf.cast(batch_past_times[:, :, 0], tf.int32), training)\n",
    "        batch_past_times_lag = self.embed_time_lag(tf.cast(batch_past_times[:, :, 1], tf.int32), training)\n",
    "         \n",
    "        ## Current\n",
    "        \n",
    "        batch_curr_question_id = self.embed_question_id(tf.cast(batch_curr_question_ids[:, 0], tf.int64))\n",
    "        batch_curr_question_part = self.embed_question_parts(tf.cast(batch_curr_question_ids[:, 1], tf.int32), training)\n",
    "        batch_curr_question_tags = self.embed_question_tags(tf.cast(batch_curr_question_tags, tf.int32), training)\n",
    "                \n",
    "        ###\n",
    "        \n",
    "        embed_past_tags = tf.reduce_sum(batch_past_question_tags, axis=2)\n",
    "        past_questions_embed = (batch_past_question_id + batch_past_question_part + \n",
    "                                batch_past_question_correct_answer + embed_past_tags)\n",
    "        past_questions_embed = self.layernorm1(past_questions_embed)\n",
    "\n",
    "        past_response_embed = (batch_past_user_answered_correct + batch_past_user_answered_answer + \n",
    "                               batch_past_times_elapsed + batch_past_times_lag)\n",
    "        past_response_embed = self.layernorm2(past_response_embed)\n",
    "     \n",
    "        embed_curr_tags = tf.reduce_sum(batch_curr_question_tags, axis=1)\n",
    "        curr_question_embed = (batch_curr_question_id + batch_curr_question_part + embed_curr_tags)\n",
    "        curr_question_embed = self.layernorm3(curr_question_embed)\n",
    "        \n",
    "        mask = self.createPaddingMask(tf.cast(batch_past_questions[:, :, 0], tf.int64), mask_value=-1)\n",
    "        \n",
    "        past_questions_x, _ = self.mha1(v=past_questions_embed, q=past_questions_embed, k=past_questions_embed, mask=mask)\n",
    "        past_response_x, _ = self.mha2(v=past_response_embed, q=past_response_embed, k=past_response_embed, mask=mask)\n",
    "        \n",
    "        past_questions_x = self.layernorm4(past_questions_embed + past_questions_x)\n",
    "        past_response_x = self.layernorm5(past_response_embed + past_response_x)\n",
    "        \n",
    "        x_past_question = layers.GlobalAveragePooling1D()(past_questions_x)\n",
    "        x_past_response = layers.GlobalAveragePooling1D()(past_response_x)\n",
    "        \n",
    "#         print(x_past_question.shape, x_past_response.shape, curr_question_embed.shape)\n",
    "        \n",
    "        x = tf.concat([x_past_question, x_past_response, curr_question_embed], axis=-1)\n",
    "        \n",
    "#         print(x.shape)\n",
    "        \n",
    "        x = self.drop_1(x, training=training)\n",
    "        x = self.dense(x)\n",
    "        x = self.batch_norm(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.drop_2(x, training=training)\n",
    "        \n",
    "        prediction = self.dense_output(x)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def createPaddingMask(self, seq, mask_value=-1):\n",
    "        seq = tf.cast(tf.math.equal(seq, mask_value), tf.float32)\n",
    "        return seq[:, tf.newaxis,  tf.newaxis, :]\n",
    "        \n",
    "\n",
    "def buildmodel(d_model, num_heads, summary=False):\n",
    "\n",
    "    basemodel = BaseModel(d_model, num_heads)\n",
    "    \n",
    "    in_1 = layers.Input(shape=(SEQ_LENGTH, 3+7))\n",
    "    in_2 = layers.Input(shape=(SEQ_LENGTH, 2))\n",
    "    in_3 = layers.Input(shape=(SEQ_LENGTH, 2))\n",
    "    \n",
    "    in_4 = layers.Input(shape=(3))\n",
    "    in_5 = layers.Input(shape=(3))\n",
    "    \n",
    "    in_6 = layers.Input(shape=(2))\n",
    "    in_7 = layers.Input(shape=(7))\n",
    "    \n",
    "    x = basemodel((in_1, in_2, in_3, in_4, in_5, in_6, in_7))\n",
    "    \n",
    "    model = models.Model(inputs=[in_1, in_2, in_3, in_4, in_5, in_6, in_7],\n",
    "                         outputs=[x])\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=8e-4), loss=losses.binary_crossentropy,\n",
    "                 metrics=[metrics.AUC(), 'acc'])\n",
    "    \n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "    \n",
    "    return model\n",
    "        \n",
    "#############################################################################   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Fold: 1\n",
      "Train users: 6169 Val users: 1543\n",
      "Epoch 1/5\n",
      "386/386 [==============================] - 4s 12ms/step - loss: 0.6633 - auc: 0.6159 - acc: 0.6552 - val_loss: 0.6140 - val_auc: 0.6780 - val_acc: 0.7071\n",
      "Epoch 2/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.5279 - auc: 0.7780 - acc: 0.7625 - val_loss: 0.6048 - val_auc: 0.7078 - val_acc: 0.7194\n",
      "Epoch 3/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.3901 - auc: 0.8878 - acc: 0.8452 - val_loss: 0.6653 - val_auc: 0.6879 - val_acc: 0.7097\n",
      "Epoch 4/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2762 - auc: 0.9464 - acc: 0.8917 - val_loss: 0.7893 - val_auc: 0.7156 - val_acc: 0.6785\n",
      "Epoch 5/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2041 - auc: 0.9712 - acc: 0.9237 - val_loss: 0.9513 - val_auc: 0.6929 - val_acc: 0.7045\n",
      "Restoring model weights from the end of the best epoch.\n",
      "************************************************************\n",
      "************************************************************\n",
      "Num Fold: 2\n",
      "Train users: 6169 Val users: 1543\n",
      "Epoch 1/5\n",
      "386/386 [==============================] - 4s 11ms/step - loss: 0.7076 - auc_1: 0.5868 - acc: 0.6160 - val_loss: 0.5688 - val_auc_1: 0.7520 - val_acc: 0.7252\n",
      "Epoch 2/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.5427 - auc_1: 0.7628 - acc: 0.7449 - val_loss: 0.5519 - val_auc_1: 0.7664 - val_acc: 0.7459\n",
      "Epoch 3/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.4110 - auc_1: 0.8733 - acc: 0.8308 - val_loss: 0.6454 - val_auc_1: 0.7162 - val_acc: 0.7356\n",
      "Epoch 4/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2889 - auc_1: 0.9403 - acc: 0.8909 - val_loss: 0.8408 - val_auc_1: 0.6689 - val_acc: 0.7285\n",
      "Epoch 5/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2272 - auc_1: 0.9625 - acc: 0.9149 - val_loss: 0.9346 - val_auc_1: 0.6807 - val_acc: 0.7006\n",
      "Restoring model weights from the end of the best epoch.\n",
      "************************************************************\n",
      "************************************************************\n",
      "Num Fold: 3\n",
      "Train users: 6170 Val users: 1542\n",
      "Epoch 1/5\n",
      "386/386 [==============================] - 4s 11ms/step - loss: 0.6703 - auc_2: 0.6027 - acc: 0.6405 - val_loss: 0.5900 - val_auc_2: 0.7100 - val_acc: 0.7108\n",
      "Epoch 2/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.5480 - auc_2: 0.7573 - acc: 0.7392 - val_loss: 0.5987 - val_auc_2: 0.7459 - val_acc: 0.6900\n",
      "Epoch 3/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.4055 - auc_2: 0.8810 - acc: 0.8303 - val_loss: 0.6573 - val_auc_2: 0.7329 - val_acc: 0.6861\n",
      "Epoch 4/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2923 - auc_2: 0.9416 - acc: 0.8887 - val_loss: 0.8206 - val_auc_2: 0.7080 - val_acc: 0.6855\n",
      "Epoch 5/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2160 - auc_2: 0.9696 - acc: 0.9194 - val_loss: 0.9234 - val_auc_2: 0.6909 - val_acc: 0.6770\n",
      "Restoring model weights from the end of the best epoch.\n",
      "************************************************************\n",
      "************************************************************\n",
      "Num Fold: 4\n",
      "Train users: 6170 Val users: 1542\n",
      "Epoch 1/5\n",
      "386/386 [==============================] - 4s 12ms/step - loss: 0.6744 - auc_3: 0.6118 - acc: 0.6374 - val_loss: 0.5932 - val_auc_3: 0.7131 - val_acc: 0.7134\n",
      "Epoch 2/5\n",
      "386/386 [==============================] - 4s 11ms/step - loss: 0.5183 - auc_3: 0.7884 - acc: 0.7637 - val_loss: 0.6369 - val_auc_3: 0.6958 - val_acc: 0.7049\n",
      "Epoch 3/5\n",
      "386/386 [==============================] - 4s 11ms/step - loss: 0.3856 - auc_3: 0.8903 - acc: 0.8441 - val_loss: 0.6738 - val_auc_3: 0.7033 - val_acc: 0.7205\n",
      "Epoch 4/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2717 - auc_3: 0.9485 - acc: 0.9005 - val_loss: 0.8814 - val_auc_3: 0.6899 - val_acc: 0.7056\n",
      "Epoch 5/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2044 - auc_3: 0.9725 - acc: 0.9241 - val_loss: 0.9784 - val_auc_3: 0.6634 - val_acc: 0.6939\n",
      "Restoring model weights from the end of the best epoch.\n",
      "************************************************************\n",
      "************************************************************\n",
      "Num Fold: 5\n",
      "Train users: 6170 Val users: 1542\n",
      "Epoch 1/5\n",
      "386/386 [==============================] - 5s 12ms/step - loss: 0.6761 - auc_4: 0.6025 - acc: 0.6417 - val_loss: 0.5843 - val_auc_4: 0.7168 - val_acc: 0.6887\n",
      "Epoch 2/5\n",
      "386/386 [==============================] - 4s 11ms/step - loss: 0.5312 - auc_4: 0.7785 - acc: 0.7561 - val_loss: 0.6071 - val_auc_4: 0.7199 - val_acc: 0.7270\n",
      "Epoch 3/5\n",
      "386/386 [==============================] - 4s 11ms/step - loss: 0.3951 - auc_4: 0.8856 - acc: 0.8399 - val_loss: 0.6581 - val_auc_4: 0.7135 - val_acc: 0.6991\n",
      "Epoch 4/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2936 - auc_4: 0.9400 - acc: 0.8840 - val_loss: 0.7813 - val_auc_4: 0.6777 - val_acc: 0.7192\n",
      "Epoch 5/5\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.2248 - auc_4: 0.9648 - acc: 0.9164 - val_loss: 1.0055 - val_auc_4: 0.6831 - val_acc: 0.6712\n",
      "Restoring model weights from the end of the best epoch.\n",
      "************************************************************\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "# 6. Training\n",
    "\n",
    "batch_size = 16\n",
    "d_model = 128\n",
    "num_heads= 4\n",
    "\n",
    "callback_early_stopping = ReturnBestEarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "list_callbacks = [callback_early_stopping]\n",
    "\n",
    "kf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=12)\n",
    "list_history, list_models = [], []\n",
    "\n",
    "for num_fold, (train_index, val_index) in enumerate(kf.split(list(unique_users),\n",
    "                                                             X_target)):\n",
    "    \n",
    "    users_train_fold = np.asarray(list(unique_users))[train_index]\n",
    "    users_val_fold = np.asarray(list(unique_users))[val_index]\n",
    "    \n",
    "    X_train_generator = RIIDDataGenerator(list(users_train_fold), dict_users, batch_size=batch_size, training=True)\n",
    "    \n",
    "    X_val_generator = RIIDDataGenerator(list(users_val_fold), dict_users, batch_size=batch_size, training=True)\n",
    "    \n",
    "    print(f'Num Fold: {num_fold + 1}')\n",
    "    print(f'Train users: {len(train_index)} Val users: {len(val_index)}')\n",
    "    \n",
    "    model = buildmodel(d_model, num_heads, summary=False)\n",
    "    \n",
    "    history = model.fit(X_train_generator,\n",
    "                        validation_data=X_val_generator,\n",
    "                        epochs=5,\n",
    "                        callbacks=list_callbacks,\n",
    "                        verbose=1)\n",
    "    \n",
    "    print('***'*20)\n",
    "    list_history.append(history)\n",
    "    list_models.append(model)\n",
    "    print('***'*20)\n",
    "    \n",
    "# tf.keras.models.save_model(list_models[0], './model/')\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "0.9312166463261825\n"
     ]
    }
   ],
   "source": [
    "# m = BaseModel()\n",
    "num_iters = 1_000\n",
    "list_score = []\n",
    "for i, batch in enumerate(X_val_generator):\n",
    "#     score = roc_auc_score(batch[1], list_models[0].predict(batch[0]))\n",
    "    score = roc_auc_score(batch[1], list_models[0].predict(batch[0]))\n",
    "    list_score.append(score)\n",
    "#     print(score)\n",
    "    if i>=num_iters:\n",
    "        break\n",
    "print('***'*10)\n",
    "print(np.mean(list_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
